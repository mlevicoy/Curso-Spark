{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1m1NiMvLslzKKW-8MY1NrabGezuQ-7DcD","authorship_tag":"ABX9TyPG+oN5LZVKKKqUCBxlODFY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["print(\"\\n\\nPREPARANDO EL ENTORNO\\n\\n\")\n","import os\n"," # Instalar SDK java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# Descargar Spark\n","!wget -q https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n","# Descomprimir la versión de Spark\n","!tar xf spark-3.3.1-bin-hadoop3.tgz\n","# Establecer las variables de entorno\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n","# Descargar findspark\n","!pip install -q findspark\n","# Descargar pyspark\n","!pip install -q pyspark\n","print(\"\\n\\n******** INSTALACIÓN CORRECTA *******\")"],"metadata":{"id":"Agc0gr9BciW4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674576347061,"user_tz":180,"elapsed":166856,"user":{"displayName":"Manuel Levicoy","userId":"01565646177464107175"}},"outputId":"840eb6e3-fa81-4fd4-b587-5729ae157215"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","PREPARANDO EL ENTORNO\n","\n","\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\n","\n","******** INSTALACIÓN CORRECTA *******\n"]}]},{"cell_type":"code","source":["# Para identificar la ruta de instalación \n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","# master, en este caso indica que es spark local y utiliza todos los cores\n","spark = SparkSession.builder.master(\"local[*]\").appName(\"Curso PySpark\").getOrCreate()"],"metadata":{"id":"0ynRkMidflSS","executionInfo":{"status":"ok","timestamp":1674577266035,"user_tz":180,"elapsed":7661,"user":{"displayName":"Manuel Levicoy","userId":"01565646177464107175"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"w_apB1yelSTL","executionInfo":{"status":"ok","timestamp":1674577283505,"user_tz":180,"elapsed":1730,"user":{"displayName":"Manuel Levicoy","userId":"01565646177464107175"}},"outputId":"76a8436f-9ef7-42ff-ef96-78bae16dce2c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f7bdc94a490>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://7e49ddf4ecd0:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Curso PySpark</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"_cgl_MrdlXzf"},"execution_count":null,"outputs":[]}]}